{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6b8c8b",
   "metadata": {
    "id": "4d6b8c8b"
   },
   "source": [
    "* * *\n",
    "<pre> NYU Paris            <i> Artificial intelligence - Summer 2023 </i></pre>\n",
    "* * *\n",
    "\n",
    "\n",
    "<h1 align=\"center\"> Lab 8: Unsupervised learning (II): similarity </h1>\n",
    "\n",
    "<pre align=\"left\"> October 26th 2023               <i> Author: Hicham Janati </i></pre>\n",
    "* * *\n",
    "\n",
    "\n",
    "##### Goals:\n",
    "- Understand the difference between distance and similarity\n",
    "- Apply this concept to face recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lzV6l0DHyN3F",
   "metadata": {
    "id": "lzV6l0DHyN3F"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SK--CJYYyf5N",
   "metadata": {
    "id": "SK--CJYYyf5N"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "root = \"/content/drive/MyDrive/Data/facerecognition\"\n",
    "sys.path.append(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d064306",
   "metadata": {
    "id": "7d064306"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5d97e",
   "metadata": {
    "id": "ccd5d97e"
   },
   "source": [
    "# Part 1: Introduction \n",
    "To explain the notion of similarity, consider the following example. We want to aggregate documents based on their topics. For the sake of simplicity, we take documents made of only a few sentences. The following cell reads the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce1a39",
   "metadata": {
    "id": "d4ce1a39"
   },
   "outputs": [],
   "source": [
    "with open(f\"{root}/text/nfts.txt\", \"r\") as docsfile:\n",
    "    documents = docsfile.read().split('\\n---\\n')\n",
    "print(f\"Number of documents: {len(documents)}\")\n",
    "print(f\"First document:\\n\\n {documents[0][:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cbdc24",
   "metadata": {
    "id": "92cbdc24"
   },
   "source": [
    "### Question 1\n",
    "The top 2 common themes of these articles are NFTs and football. We want to classify them based on the extent to which these themes are present. To do so, write a function that takes a document in argument (a string) and returns a vectors containing the number of times the words \"nft\", \"nfts\", \"football\", \"footballer\" are present, in that order. \n",
    "\n",
    "For example, `text_to_vec(\"a footballer bought two NFTs: 1 digital art NFT and 1 music NFT\")` should return: `[2, 1, 0, 1]`.\n",
    "\n",
    "*Hint: Check the documentation of these string and list methods: (`string.lower` `string.split` `list.count`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1652ee",
   "metadata": {
    "id": "1e1652ee"
   },
   "outputs": [],
   "source": [
    "def text_to_vec(text, dictionary=[\"nft\", \"nfts\", \"football\", \"footballer\", \"footballers\"]):\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446b7a1",
   "metadata": {
    "id": "c446b7a1"
   },
   "source": [
    "### Question 2\n",
    "To make things simple, modify the function `text_to_vec` so that it aggregates the counts for [\"nft, \"nfts\"] and [\"football\", \"footballer\", \"footballers\"]. The same example above should then return: `[3, 2]`. Then transform the list of documents to a list of vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96567870",
   "metadata": {
    "id": "96567870"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33f6172",
   "metadata": {
    "id": "c33f6172"
   },
   "source": [
    "### Question 3\n",
    "Print the vector of each documents. Intuitively, based only on these counts what documents do you consider similar / dissimilar ? Use the function below to visualize the vectors. Is this visualization in agreement with your intuition ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaef039",
   "metadata": {
    "id": "fcaef039"
   },
   "outputs": [],
   "source": [
    "def plot_vectors(vectors):\n",
    "    colors = [\"indianred\", \"purple\", \"orange\", \"forestgreen\", \"navy\"]\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for ii, vec in enumerate(vectors):\n",
    "        plt.arrow(0,0,vec[0] * 0.95, vec[1] * 0.97, \n",
    "        shape='full', color=colors[ii], length_includes_head=True, \n",
    "        zorder=0, head_length=0.2, head_width=0.2, alpha=0.6, lw=2)\n",
    "        plt.scatter(vec[0], vec[1], marker=rf\"${ii}$\", color=colors[ii], s=200)\n",
    "    plt.grid()\n",
    "    plt.xlim([-1, None])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f6c3c",
   "metadata": {
    "id": "038f6c3c"
   },
   "source": [
    "### Question 4 \n",
    "Normalize the vectors by their norm so that their Euclidean norm $\\|.\\|_2$ is equal to 1. Visualize the new vectors. What to you observe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U3fCuJ2RBWp7",
   "metadata": {
    "id": "U3fCuJ2RBWp7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d80487e",
   "metadata": {
    "id": "9d80487e"
   },
   "source": [
    "### Question 5\n",
    "Compute the Euclidean distance between two unit-norm vectors $x$ and $y$. Can you deduce from it a notion of similarity between two vectors $x$ and $y$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Unr2c-lBYFE",
   "metadata": {
    "id": "8Unr2c-lBYFE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "547c9dae",
   "metadata": {
    "id": "547c9dae"
   },
   "source": [
    "# Part 2: Similarity score for face recognition\n",
    "\n",
    "The following cell reads the facial images dataset of celebrities and images of non-celebrities, here referred to as \"impostors\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GZy8qy_s9Ula",
   "metadata": {
    "id": "GZy8qy_s9Ula"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "labels = []\n",
    "imgs = []\n",
    "celebs = [\"thorne\", \"mac\", \"kendrick\", \"jolie\", \"hathaway\", \"arnold\", \"benedict\", \"impostors\"]\n",
    "genders_list = [1, 0, 1, 1, 1, 0, 0, None]\n",
    "genders = []\n",
    "\n",
    "\n",
    "for label, name in enumerate(celebs):\n",
    "    imgpath = f\"{root}/imgs/{name}/\"\n",
    "    gender = genders_list[label]\n",
    "    for ii, filename in enumerate(glob.glob(imgpath + \"*.jpg\")):\n",
    "        img = cv2.imread(filename)\n",
    "        if img is None:\n",
    "            print(filename)\n",
    "            break\n",
    "        img = cv2.resize(img, (112, 112))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img.div_(255).sub_(0.5).div_(0.5)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "        if gender is not None:\n",
    "            genders.append(gender)\n",
    "\n",
    "with open(f\"{root}/imgs/gender.txt\", \"r\") as genderfile:\n",
    "    gender_imp = genderfile.read().split(',\\n')\n",
    "gender_imp = np.array(gender_imp).astype(int)\n",
    "\n",
    "genders.extend(gender_imp)\n",
    "imgs = torch.stack(imgs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "labels[labels < len(celebs) - 1] = 0\n",
    "labels[labels == len(celebs) - 1] = 1\n",
    "genders = np.array(genders)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print(imgs.shape, labels.shape, genders.shape)\n",
    "print(\"pct of imposters = \", 100 * labels.float().mean().item())\n",
    "print(\"pct of males = \", 100 * (1- genders.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ycfLsx9T-6YM",
   "metadata": {
    "id": "ycfLsx9T-6YM"
   },
   "source": [
    "An embedding is a neural network transforming a sample (image, text, data ..) to multi-dimensional space -- generally with a lower dimension than the input space. Such that this new representation is more \"meaningful\". For example, a good text embedding would provide a representation where words having a close meaning would be geometrically closer. Here we use an embedding for facial recognition which is already pre-trained i.e we only read the weights which are already optimized. \n",
    "\n",
    "In general, the goal is to learn a neural net such that by computing the similarity score, it is very easy to detect impostors from genuine samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dac2df",
   "metadata": {
    "id": "c3dac2df"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from backbones import get_model\n",
    "modelpath = f\"{root}/models/backbone-r100.pth\"\n",
    "network = \"r100\"\n",
    "output_dir = \"outputs/\"\n",
    "batch_size = 128\n",
    "device = \"cpu\"\n",
    "# load backbone\n",
    "model = get_model(network, fp16=False)\n",
    "model.load_state_dict(torch.load(modelpath, map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1wR_8_6uREAf",
   "metadata": {
    "id": "1wR_8_6uREAf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "A86wYuIUREr-",
   "metadata": {
    "id": "A86wYuIUREr-"
   },
   "source": [
    "### Question 6\n",
    "Use the loaded pre-trained model to compute the embedding of all the images. The resulting object should be one matrix containing the embeddings of all images. Use GPUs for speed-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VCzMOivMfk9_",
   "metadata": {
    "id": "VCzMOivMfk9_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "JiMHRxLYRa2M",
   "metadata": {
    "id": "JiMHRxLYRa2M"
   },
   "source": [
    "### Question 7\n",
    "Compute the pairwise matrices of Euclidean distances and similarity scores. Check the documentation of `sklearn.metrics.pairwise` for help. Visualize the obtained matrices with `plt.imshow`. Add a `plt.colorbar()`. What do you notice ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GgEE3KihSW1x",
   "metadata": {
    "id": "GgEE3KihSW1x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wTGtukOARuH1",
   "metadata": {
    "id": "wTGtukOARuH1"
   },
   "source": [
    "### Question 8\n",
    "The following cell computes the correct acceptance rate as a function of the false acceptance rate while varying the threshold on the cosine similarity score for both males and females. What do you conclude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iMIrsSaICvHx",
   "metadata": {
    "id": "iMIrsSaICvHx"
   },
   "outputs": [],
   "source": [
    "from evaluation import Evaluation\n",
    "from metrics import Metrics\n",
    "\n",
    "\n",
    "eval = Evaluation(embeddings, labels, genders)\n",
    "scores = eval.eval(model)\n",
    "Metrics(scores).plot_roc()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
